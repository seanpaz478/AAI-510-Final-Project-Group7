{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN45uos6xdrC6GNI2A67jGx",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "6a16c00e75e241fd83b08abf04b9ad3b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_892689b447c549268e86ff0543b36221",
              "IPY_MODEL_288da731565747c9b114eac0bd9091ba",
              "IPY_MODEL_bc565e9b6b1b491792cf14881dd04a58"
            ],
            "layout": "IPY_MODEL_c117ed3031d449db95b3cac91269e12d"
          }
        },
        "892689b447c549268e86ff0543b36221": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_840e78901ae34de290a72e18f9ae57a4",
            "placeholder": "​",
            "style": "IPY_MODEL_a6fa2b1c184549169d3ccb0e05300042",
            "value": "100%"
          }
        },
        "288da731565747c9b114eac0bd9091ba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2ea04f7e5f824ae98e0d2f48010f55c8",
            "max": 193852,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9eb16509da5e4294827ec429c9bf04c7",
            "value": 193852
          }
        },
        "bc565e9b6b1b491792cf14881dd04a58": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1cdb07e72b954d46a5837739ea39aeb2",
            "placeholder": "​",
            "style": "IPY_MODEL_18d41fa1825048948ae4e46cb2df4677",
            "value": " 193852/193852 [07:33&lt;00:00, 358.01it/s]"
          }
        },
        "c117ed3031d449db95b3cac91269e12d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "840e78901ae34de290a72e18f9ae57a4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a6fa2b1c184549169d3ccb0e05300042": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2ea04f7e5f824ae98e0d2f48010f55c8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9eb16509da5e4294827ec429c9bf04c7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1cdb07e72b954d46a5837739ea39aeb2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "18d41fa1825048948ae4e46cb2df4677": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/seanpaz478/AAI-510-Final-Project-Group7/blob/main/Usd%2C_ML%2C_Final_Group_Project%2C_Stacking_w_inference_time_(YSternberg).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "6a16c00e75e241fd83b08abf04b9ad3b",
            "892689b447c549268e86ff0543b36221",
            "288da731565747c9b114eac0bd9091ba",
            "bc565e9b6b1b491792cf14881dd04a58",
            "c117ed3031d449db95b3cac91269e12d",
            "840e78901ae34de290a72e18f9ae57a4",
            "a6fa2b1c184549169d3ccb0e05300042",
            "2ea04f7e5f824ae98e0d2f48010f55c8",
            "9eb16509da5e4294827ec429c9bf04c7",
            "1cdb07e72b954d46a5837739ea39aeb2",
            "18d41fa1825048948ae4e46cb2df4677"
          ]
        },
        "id": "BsdzMShR2qxz",
        "outputId": "17098d19-527f-4c20-b20e-a056ffe9a59a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Checkpoint directory is ready at: /content/drive/My Drive/SpamClassifierProject_Checkpoints\n",
            "Data loaded. Starting text preprocessing...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/193852 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6a16c00e75e241fd83b08abf04b9ad3b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Text preprocessing complete.\n",
            "Created a data-driven spam vocabulary with 50 words.\n",
            "\n",
            "--- Creating the full feature set... ---\n",
            "Feature creation complete.\n",
            "\n",
            "--- Tuning Base Models ---\n",
            "Found checkpoint for lgbm. Loading pre-tuned model.\n",
            "Loaded best parameters for lgbm: {'clf__learning_rate': 0.1, 'clf__n_estimators': 200, 'clf__num_leaves': 50}\n",
            "\n",
            "Found checkpoint for rf. Loading pre-tuned model.\n",
            "Loaded best parameters for rf: {'clf__max_depth': None, 'clf__min_samples_split': 5, 'clf__n_estimators': 200}\n",
            "\n",
            "--- Generating Level 1 features using tuned base models... ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Level 1 features generated.\n",
            "\n",
            "--- Tuning the Meta-Model ---\n",
            "Found checkpoint for Meta-Model. Loading pre-tuned model.\n",
            "Loaded best parameters for Meta-Model: {'classifier__C': 1.0, 'classifier__penalty': 'l2'}\n",
            "\n",
            "\n",
            "################################################################################\n",
            "# FINAL TUNED MODEL PERFORMANCE\n",
            "################################################################################\n",
            "Classification Report for the Tuned Model:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     Ham (0)       0.99      0.99      0.99     25540\n",
            "    Spam (1)       0.99      0.99      0.99     22923\n",
            "\n",
            "    accuracy                           0.99     48463\n",
            "   macro avg       0.99      0.99      0.99     48463\n",
            "weighted avg       0.99      0.99      0.99     48463\n",
            "\n",
            "\n",
            "Final Performance Metrics:\n",
            "- Tuned Accuracy: 0.9895\n",
            "- Tuned Spam F1-Score: 0.9889\n",
            "- Tuned MCC: 0.9789\n",
            "- Tuned AUC: 0.9993\n",
            "- Inference Time (ms): 19245\n",
            "\n",
            "Hyperparameter tuning complete.\n",
            "\n",
            "--- Saving final artifacts for the tuned model stack... ---\n",
            "Final artifacts will be saved in: /content/drive/My Drive/SpamClassifierProject_TunedStacking/tuned_run_2025-06-22_23-51-35\n",
            "Tuned base and meta models saved successfully.\n",
            "Performance reports, parameters, and vocabulary saved successfully.\n",
            "\n",
            "All final artifacts have been saved.\n"
          ]
        }
      ],
      "source": [
        "import re\n",
        "import os\n",
        "import json\n",
        "from datetime import datetime\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import joblib\n",
        "from time import time # MODIFICATION: Added the time library\n",
        "\n",
        "# NLTK imports - ensure you have these downloaded\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.tokenize import word_tokenize, sent_tokenize\n",
        "import nltk\n",
        "\n",
        "# Scikit-learn imports\n",
        "from sklearn.model_selection import train_test_split, cross_val_predict, GridSearchCV\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import (\n",
        "    classification_report,\n",
        "    matthews_corrcoef,\n",
        "    roc_auc_score,\n",
        ")\n",
        "\n",
        "# Model imports\n",
        "import lightgbm as lgb\n",
        "\n",
        "# Progress bar for pandas\n",
        "from tqdm.auto import tqdm\n",
        "tqdm.pandas()\n",
        "\n",
        "# Google Drive integration\n",
        "from google.colab import drive\n",
        "\n",
        "# NLTK download\n",
        "for resource in ['punkt', 'stopwords', 'wordnet', 'punkt_tab']:\n",
        "    nltk.download(resource, quiet=True)\n",
        "\n",
        "# --- Feature Engineering Setup ---\n",
        "\n",
        "PATTERNS = {\n",
        "    \"url\": re.compile(r\"http[s]?://\\S+\"),\n",
        "    \"email\": re.compile(r\"\\S+@\\S+\"),\n",
        "    \"phone\": re.compile(r\"\\b(?:\\d{3}[-.\\s]?)?\\d{3}[-.\\s]?\\d{4}\\b\"),\n",
        "    \"hyperlink\": re.compile(r\"(http|www|\\.com)\"),\n",
        "    \"currency\": re.compile(r\"[$£€]\"),\n",
        "    \"non_alnum\": re.compile(r\"[^a-zA-Z0-9\\s]\"),\n",
        "    \"digit\": re.compile(r\"\\d\"),\n",
        "    \"upper_word\": re.compile(r\"\\b[A-Z]{2,}\\b\"),\n",
        "    \"repeat_char\": re.compile(r\"(.)\\1{2,}\"),\n",
        "}\n",
        "\n",
        "stop_words = set(stopwords.words(\"english\"))\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "def preprocess_text(text):\n",
        "    \"\"\"\n",
        "    Cleans and preprocesses the raw text by removing URLs, emails, and non-alphanumeric characters,\n",
        "    tokenizing, lemmatizing, and removing stopwords.\n",
        "    \"\"\"\n",
        "    if not isinstance(text, str): return \"\"\n",
        "    text = PATTERNS[\"url\"].sub(\" \", text)\n",
        "    text = PATTERNS[\"email\"].sub(\" \", text)\n",
        "    text = PATTERNS[\"non_alnum\"].sub(\" \", text).lower()\n",
        "    tokens = word_tokenize(text)\n",
        "    return \" \".join([lemmatizer.lemmatize(t) for t in tokens if t not in stop_words and len(t) > 1])\n",
        "\n",
        "def safe_division(numerator, denominator):\n",
        "    \"\"\"Performs division, returning 0 if the denominator is 0.\"\"\"\n",
        "    return numerator / denominator.clip(lower=1)\n",
        "\n",
        "def create_features(df, spam_vocab=None):\n",
        "    \"\"\"\n",
        "    Generates a full set of features from the input text data.\n",
        "\n",
        "    Args:\n",
        "        df (pd.DataFrame): DataFrame containing 'text' and 'processed_text' columns.\n",
        "        spam_vocab (set, optional): A set of spam-related words. Defaults to None.\n",
        "\n",
        "    Returns:\n",
        "        pd.DataFrame: The original DataFrame with new feature columns added.\n",
        "    \"\"\"\n",
        "    features_df = df.copy()\n",
        "    raw_text = features_df[\"text\"].astype(str)\n",
        "    processed_tokens = features_df[\"processed_text\"].str.split().fillna(\"\").apply(list)\n",
        "\n",
        "    # --- Core features ---\n",
        "    features_df[\"feat_char_count\"] = raw_text.str.len()\n",
        "    features_df[\"feat_word_count\"] = processed_tokens.str.len()\n",
        "    features_df[\"feat_hyperlink_count\"] = raw_text.str.lower().str.count(PATTERNS[\"hyperlink\"])\n",
        "    features_df[\"feat_digit_count\"] = raw_text.str.count(PATTERNS[\"digit\"])\n",
        "\n",
        "    # Calculate spam word count if vocab is provided\n",
        "    if spam_vocab:\n",
        "        spam_word_count = processed_tokens.apply(lambda tokens: sum(1 for word in tokens if word in spam_vocab))\n",
        "        features_df[\"feat_spam_word_count\"] = spam_word_count\n",
        "\n",
        "    # --- Detailed linguistic features ---\n",
        "    features_df[\"feat_sentence_count\"] = raw_text.apply(lambda x: len(sent_tokenize(x))).clip(lower=1)\n",
        "    features_df[\"feat_paragraph_count\"] = raw_text.str.count(r'\\n\\n') + 1\n",
        "    features_df[\"feat_word_diversity\"] = processed_tokens.apply(lambda x: len(set(x)))\n",
        "    features_df[\"feat_uppercase_char_count\"] = raw_text.str.count(r\"[A-Z]\")\n",
        "\n",
        "    # --- Ratio-based features ---\n",
        "    features_df[\"feat_avg_word_len\"] = safe_division(raw_text.str.replace(\" \", \"\").str.len(), features_df[\"feat_word_count\"])\n",
        "    features_df[\"feat_word_diversity_ratio\"] = safe_division(features_df[\"feat_word_diversity\"], features_df[\"feat_word_count\"])\n",
        "    features_df[\"feat_uppercase_char_ratio\"] = safe_division(features_df[\"feat_uppercase_char_count\"], features_df[\"feat_char_count\"])\n",
        "    features_df[\"feat_word_per_sentence\"] = safe_division(features_df[\"feat_word_count\"], features_df[\"feat_sentence_count\"])\n",
        "    features_df[\"feat_word_per_paragraph\"] = safe_division(features_df[\"feat_word_count\"], features_df[\"feat_paragraph_count\"])\n",
        "    features_df[\"feat_sentence_per_paragraph\"] = safe_division(features_df[\"feat_sentence_count\"], features_df[\"feat_paragraph_count\"])\n",
        "    if spam_vocab:\n",
        "        features_df[\"feat_spam_word_ratio\"] = safe_division(features_df[\"feat_spam_word_count\"], features_df[\"feat_word_count\"])\n",
        "\n",
        "    # Final cleanup\n",
        "    feature_cols = [c for c in features_df.columns if c.startswith(\"feat_\")]\n",
        "    features_df[feature_cols] = features_df[feature_cols].fillna(0)\n",
        "    return features_df\n",
        "\n",
        "# ==============================================================================\n",
        "# MAIN EXECUTION BLOCK\n",
        "# ==============================================================================\n",
        "if __name__ == '__main__':\n",
        "    # --- Step 1: Load and Preprocess Data ---\n",
        "    if 'google.colab' in str(get_ipython()):\n",
        "        drive.mount('/content/drive', force_remount=True)\n",
        "        file_path = '/content/drive/My Drive/spam_Emails_data.csv'\n",
        "        # Directory for saving progress and final models\n",
        "        CHECKPOINT_DIR = '/content/drive/My Drive/SpamClassifierProject_Checkpoints'\n",
        "        os.makedirs(CHECKPOINT_DIR, exist_ok=True)\n",
        "        print(f\"Checkpoint directory is ready at: {CHECKPOINT_DIR}\")\n",
        "    else:\n",
        "        # Fallback for local execution\n",
        "        file_path = 'spam_Emails_data.csv' # Assumes file is in the same directory\n",
        "        CHECKPOINT_DIR = None\n",
        "        print(\"Google Drive not connected. Checkpointing is disabled.\")\n",
        "\n",
        "    df = pd.read_csv(file_path)\n",
        "    df.dropna(subset=['label'], inplace=True)\n",
        "    df['label'] = df['label'].str.strip().str.capitalize().map({'Ham': 0, 'Spam': 1})\n",
        "    df.dropna(subset=['label'], inplace=True)\n",
        "    df['label'] = df['label'].astype(int)\n",
        "    print(\"Data loaded. Starting text preprocessing...\")\n",
        "    df['processed_text'] = df['text'].progress_apply(preprocess_text)\n",
        "    y = df['label']\n",
        "    print(\"Text preprocessing complete.\")\n",
        "\n",
        "    # --- Step 2: Create Data-Driven Spam Vocabulary ---\n",
        "    temp_train_df, _ = train_test_split(df, test_size=0.3, random_state=42, stratify=y)\n",
        "    tfidf_vocab_gen = TfidfVectorizer(max_features=50, stop_words='english')\n",
        "    tfidf_vocab_gen.fit(temp_train_df['processed_text'])\n",
        "    DATA_DRIVEN_SPAM_VOCAB = set(tfidf_vocab_gen.get_feature_names_out())\n",
        "    print(f\"Created a data-driven spam vocabulary with {len(DATA_DRIVEN_SPAM_VOCAB)} words.\")\n",
        "\n",
        "    # --- Step 3: Create Full Feature Set ---\n",
        "    print(\"\\n--- Creating the full feature set... ---\")\n",
        "    features_df = create_features(df.drop('label', axis=1), spam_vocab=DATA_DRIVEN_SPAM_VOCAB)\n",
        "    print(\"Feature creation complete.\")\n",
        "\n",
        "    # --- Step 4: Define Hyperparameter Grids & Prepare Data for Tuning ---\n",
        "    lgbm_param_grid = {\n",
        "        'clf__n_estimators': [100, 200], 'clf__learning_rate': [0.05, 0.1], 'clf__num_leaves': [31, 50]\n",
        "    }\n",
        "    rf_param_grid = {\n",
        "        'clf__n_estimators': [100, 200], 'clf__max_depth': [10, 20, None], 'clf__min_samples_split': [2, 5]\n",
        "    }\n",
        "    logistic_param_grid = {\n",
        "        'classifier__C': [0.1, 1.0, 10.0], 'classifier__penalty': ['l1', 'l2']\n",
        "    }\n",
        "\n",
        "    # Split data for training and testing\n",
        "    X_base_train, X_base_test, y_train, y_test = train_test_split(\n",
        "        features_df, y, test_size=0.25, random_state=42, stratify=y\n",
        "    )\n",
        "    # The meta features are the same as the base features in this simplified setup\n",
        "    X_meta_train, X_meta_test, _, _ = train_test_split(\n",
        "        features_df, y, test_size=0.25, random_state=42, stratify=y\n",
        "    )\n",
        "\n",
        "    # --- Step 5: Tune Base Models with Checkpointing ---\n",
        "    print(\"\\n--- Tuning Base Models ---\")\n",
        "    base_preprocessor = ColumnTransformer(\n",
        "        transformers=[\n",
        "            ('tfidf', TfidfVectorizer(max_features=2500), 'processed_text'),\n",
        "            ('numeric', StandardScaler(), [c for c in X_base_train.columns if c.startswith('feat_')])\n",
        "        ], remainder='drop'\n",
        "    )\n",
        "    base_estimators_for_tuning = {\n",
        "        'lgbm': (Pipeline([('preprocessor', base_preprocessor), ('clf', lgb.LGBMClassifier(random_state=42))]), lgbm_param_grid),\n",
        "        'rf': (Pipeline([('preprocessor', base_preprocessor), ('clf', RandomForestClassifier(random_state=42))]), rf_param_grid)\n",
        "    }\n",
        "\n",
        "    best_base_estimators = {}\n",
        "    best_base_params = {}\n",
        "\n",
        "    for name, (pipeline, param_grid) in base_estimators_for_tuning.items():\n",
        "        checkpoint_path = os.path.join(CHECKPOINT_DIR, f'base_model_{name}_checkpoint.joblib') if CHECKPOINT_DIR else None\n",
        "\n",
        "        if checkpoint_path and os.path.exists(checkpoint_path):\n",
        "            print(f\"Found checkpoint for {name}. Loading pre-tuned model.\")\n",
        "            checkpoint_data = joblib.load(checkpoint_path)\n",
        "            best_base_estimators[name] = checkpoint_data['estimator']\n",
        "            best_base_params[name] = checkpoint_data['params']\n",
        "            print(f\"Loaded best parameters for {name}: {best_base_params[name]}\\n\")\n",
        "        else:\n",
        "            print(f\"No checkpoint found for {name}. Running GridSearchCV...\")\n",
        "            grid_search = GridSearchCV(pipeline, param_grid, cv=3, scoring='roc_auc', n_jobs=-1, verbose=1)\n",
        "            grid_search.fit(X_base_train, y_train)\n",
        "\n",
        "            best_base_estimators[name] = grid_search.best_estimator_\n",
        "            best_base_params[name] = grid_search.best_params_\n",
        "\n",
        "            print(f\"Best parameters for {name}: {grid_search.best_params_}\")\n",
        "            print(f\"Best AUC score for {name}: {grid_search.best_score_:.4f}\\n\")\n",
        "\n",
        "            if checkpoint_path:\n",
        "                print(f\"Saving checkpoint for {name} to Google Drive...\")\n",
        "                checkpoint_data = {'estimator': grid_search.best_estimator_, 'params': grid_search.best_params_}\n",
        "                joblib.dump(checkpoint_data, checkpoint_path)\n",
        "                print(\"Checkpoint saved.\\n\")\n",
        "\n",
        "    # --- Step 6: Generate Level 1 Features using Tuned Models ---\n",
        "    print(\"--- Generating Level 1 features using tuned base models... ---\")\n",
        "    oof_train_preds_tuned = []\n",
        "    test_preds_tuned = []\n",
        "\n",
        "    for name, best_model in best_base_estimators.items():\n",
        "        oof_preds = cross_val_predict(best_model, X_base_train, y_train, cv=3, method='predict_proba', n_jobs=-1)[:, 1]\n",
        "        oof_train_preds_tuned.append(pd.Series(oof_preds, name=f\"pred_{name}_tuned\", index=X_base_train.index))\n",
        "\n",
        "        test_p = best_model.predict_proba(X_base_test)[:, 1]\n",
        "        test_preds_tuned.append(pd.Series(test_p, name=f\"pred_{name}_tuned\", index=X_base_test.index))\n",
        "\n",
        "    X_meta_train_final_tuned = pd.concat([X_meta_train] + oof_train_preds_tuned, axis=1)\n",
        "    X_meta_test_final_tuned = pd.concat([X_meta_test] + test_preds_tuned, axis=1)\n",
        "    print(\"Level 1 features generated.\")\n",
        "\n",
        "    # --- Step 7: Tune the Meta-Model with Checkpointing ---\n",
        "    print(\"\\n--- Tuning the Meta-Model ---\")\n",
        "    meta_model_checkpoint_path = os.path.join(CHECKPOINT_DIR, 'meta_model_checkpoint.joblib') if CHECKPOINT_DIR else None\n",
        "\n",
        "    best_meta_model = None\n",
        "    best_meta_params = None\n",
        "\n",
        "    if meta_model_checkpoint_path and os.path.exists(meta_model_checkpoint_path):\n",
        "        print(\"Found checkpoint for Meta-Model. Loading pre-tuned model.\")\n",
        "        checkpoint_data = joblib.load(meta_model_checkpoint_path)\n",
        "        best_meta_model = checkpoint_data['estimator']\n",
        "        best_meta_params = checkpoint_data['params']\n",
        "        print(f\"Loaded best parameters for Meta-Model: {best_meta_params}\\n\")\n",
        "    else:\n",
        "        print(\"No checkpoint found for Meta-Model. Running GridSearchCV...\")\n",
        "        meta_numeric_features_tuned = [c for c in X_meta_train_final_tuned.columns if c.startswith('feat_') or c.startswith('pred_')]\n",
        "        meta_preprocessor = ColumnTransformer(\n",
        "            transformers=[\n",
        "                ('tfidf', TfidfVectorizer(max_features=2500), 'processed_text'),\n",
        "                ('numeric', StandardScaler(), meta_numeric_features_tuned)\n",
        "            ], remainder='drop'\n",
        "        )\n",
        "        meta_model_pipeline = Pipeline([\n",
        "            ('preprocessor', meta_preprocessor),\n",
        "            ('classifier', LogisticRegression(random_state=42, solver='liblinear'))\n",
        "        ])\n",
        "\n",
        "        meta_grid_search = GridSearchCV(meta_model_pipeline, logistic_param_grid, cv=3, scoring='roc_auc', n_jobs=-1, verbose=1)\n",
        "        meta_grid_search.fit(X_meta_train_final_tuned, y_train)\n",
        "\n",
        "        best_meta_model = meta_grid_search.best_estimator_\n",
        "        best_meta_params = meta_grid_search.best_params_\n",
        "\n",
        "        print(f\"Best parameters for Meta-Model: {meta_grid_search.best_params_}\")\n",
        "        print(f\"Best AUC score for Meta-Model on training data: {meta_grid_search.best_score_:.4f}\\n\")\n",
        "\n",
        "        if meta_model_checkpoint_path:\n",
        "            print(\"Saving checkpoint for Meta-Model to Google Drive...\")\n",
        "            checkpoint_data = {'estimator': best_meta_model, 'params': best_meta_params}\n",
        "            joblib.dump(checkpoint_data, meta_model_checkpoint_path)\n",
        "            print(\"Checkpoint saved.\\n\")\n",
        "\n",
        "    # --- Step 8: Evaluate the Final, Fully-Tuned Stacking Model ---\n",
        "    print(f\"\\n{'#'*80}\\n# FINAL TUNED MODEL PERFORMANCE\\n{'#'*80}\")\n",
        "\n",
        "    # MODIFICATION: Start timing the inference step in milliseconds\n",
        "    inference_start_time = int(time() * 1000)\n",
        "\n",
        "    y_pred_tuned = best_meta_model.predict(X_meta_test_final_tuned)\n",
        "    y_proba_tuned = best_meta_model.predict_proba(X_meta_test_final_tuned)[:, 1]\n",
        "\n",
        "    # MODIFICATION: End timing and calculate the duration in milliseconds\n",
        "    inference_end_time = int(time() * 1000)\n",
        "    inference_time_ms = inference_end_time - inference_start_time\n",
        "\n",
        "    report_str = classification_report(y_test, y_pred_tuned, target_names=['Ham (0)', 'Spam (1)'])\n",
        "    report_dict = classification_report(y_test, y_pred_tuned, output_dict=True)\n",
        "\n",
        "    print(\"Classification Report for the Tuned Model:\")\n",
        "    print(report_str)\n",
        "\n",
        "    final_metrics = {\n",
        "        'Tuned Accuracy': f\"{report_dict['accuracy']:.4f}\",\n",
        "        'Tuned Spam F1-Score': f\"{report_dict['1']['f1-score']:.4f}\",\n",
        "        'Tuned MCC': f\"{matthews_corrcoef(y_test, y_pred_tuned):.4f}\",\n",
        "        'Tuned AUC': f\"{roc_auc_score(y_test, y_proba_tuned):.4f}\",\n",
        "        # MODIFICATION: Add the inference time in milliseconds to the final metrics dictionary\n",
        "        'Inference Time (ms)': inference_time_ms\n",
        "    }\n",
        "\n",
        "    print(\"\\nFinal Performance Metrics:\")\n",
        "    for metric, value in final_metrics.items():\n",
        "        print(f\"- {metric}: {value}\")\n",
        "    print(\"\\nHyperparameter tuning complete.\")\n",
        "\n",
        "    # --- Step 9: Save Final Tuned Model Artifacts ---\n",
        "    if CHECKPOINT_DIR:\n",
        "        print(\"\\n--- Saving final artifacts for the tuned model stack... ---\")\n",
        "\n",
        "        BASE_PROJECT_PATH = '/content/drive/My Drive/SpamClassifierProject_TunedStacking'\n",
        "        timestamp = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
        "        RUN_SPECIFIC_PATH = os.path.join(BASE_PROJECT_PATH, f\"tuned_run_{timestamp}\")\n",
        "        os.makedirs(RUN_SPECIFIC_PATH, exist_ok=True)\n",
        "\n",
        "        print(f\"Final artifacts will be saved in: {RUN_SPECIFIC_PATH}\")\n",
        "\n",
        "        # Save each tuned base model\n",
        "        for name, model in best_base_estimators.items():\n",
        "            joblib.dump(model, os.path.join(RUN_SPECIFIC_PATH, f'tuned_base_model_{name}.joblib'))\n",
        "\n",
        "        # Save the tuned meta model\n",
        "        joblib.dump(best_meta_model, os.path.join(RUN_SPECIFIC_PATH, 'tuned_meta_model.joblib'))\n",
        "        print(\"Tuned base and meta models saved successfully.\")\n",
        "\n",
        "        # Save performance reports and vocabulary\n",
        "        summary_report = {\n",
        "            'Final Performance Metrics': final_metrics,\n",
        "            'Best Base Model Parameters': best_base_params,\n",
        "            'Best Meta Model Parameters': best_meta_params\n",
        "        }\n",
        "        with open(os.path.join(RUN_SPECIFIC_PATH, 'summary_report.json'), 'w') as f:\n",
        "            json.dump(summary_report, f, indent=4)\n",
        "        with open(os.path.join(RUN_SPECIFIC_PATH, 'classification_report.txt'), 'w') as f:\n",
        "            f.write(report_str)\n",
        "        joblib.dump(DATA_DRIVEN_SPAM_VOCAB, os.path.join(RUN_SPECIFIC_PATH, 'spam_vocabulary.joblib'))\n",
        "        print(\"Performance reports, parameters, and vocabulary saved successfully.\")\n",
        "\n",
        "        print(\"\\nAll final artifacts have been saved.\")\n",
        "    else:\n",
        "        print(\"\\nGoogle Drive not connected. Skipping final artifact saving.\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "    # --- Step 9: Evaluate the Final, Fully-Tuned Stacking Model ---\n",
        "    print(f\"\\n{'#'*80}\\n# FINAL TUNED MODEL PERFORMANCE\\n{'#'*80}\")\n",
        "\n",
        "    # MODIFICATION: Deconstruct the pipeline to time steps separately\n",
        "    preprocessor = best_meta_model.named_steps['preprocessor']\n",
        "    classifier = best_meta_model.named_steps['classifier']\n",
        "\n",
        "    # Time the Vectorization / Transformation step\n",
        "    transform_start_time = int(time() * 1000)\n",
        "    X_test_transformed = preprocessor.transform(X_meta_test_final_tuned)\n",
        "    transform_end_time = int(time() * 1000)\n",
        "    transform_time_ms = transform_end_time - transform_start_time\n",
        "\n",
        "    # Time the Prediction step\n",
        "    predict_start_time = int(time() * 1000)\n",
        "    y_pred_tuned = classifier.predict(X_test_transformed)\n",
        "    y_proba_tuned = classifier.predict_proba(X_test_transformed)[:, 1]\n",
        "    predict_end_time = int(time() * 1000)\n",
        "    predict_time_ms = predict_end_time - predict_start_time\n",
        "\n",
        "    report_str = classification_report(y_test, y_pred_tuned, target_names=['Ham (0)', 'Spam (1)'])\n",
        "    report_dict = classification_report(y_test, y_pred_tuned, output_dict=True)\n",
        "\n",
        "    print(\"Classification Report for the Tuned Model:\")\n",
        "    print(report_str)\n",
        "\n",
        "    final_metrics = {\n",
        "        'Tuned Accuracy': f\"{report_dict['accuracy']:.4f}\",\n",
        "        'Tuned Spam F1-Score': f\"{report_dict['1']['f1-score']:.4f}\",\n",
        "        'Tuned MCC': f\"{matthews_corrcoef(y_test, y_pred_tuned):.4f}\",\n",
        "        'Tuned AUC': f\"{roc_auc_score(y_test, y_proba_tuned):.4f}\",\n",
        "        'Vectorization Time (ms)': transform_time_ms,\n",
        "        'Prediction Time (ms)': predict_time_ms\n",
        "    }\n",
        "\n",
        "    print(\"\\nFinal Performance Metrics:\")\n",
        "    for metric, value in final_metrics.items():\n",
        "        print(f\"- {metric}: {value}\")\n",
        "    print(\"\\nHyperparameter tuning complete.\")\n",
        "\n",
        "    # --- Step 10: Save Final Tuned Model Artifacts ---\n",
        "    print(\"\\n--- Saving final artifacts... ---\")\n",
        "\n",
        "    BASE_PROJECT_PATH = 'SpamClassifierProject_TunedStacking'\n",
        "    timestamp = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
        "    RUN_SPECIFIC_PATH = os.path.join(BASE_PROJECT_PATH, f\"tuned_run_{timestamp}\")\n",
        "    os.makedirs(RUN_SPECIFIC_PATH, exist_ok=True)\n",
        "\n",
        "    print(f\"Final artifacts will be saved in: {RUN_SPECIFIC_PATH}\")\n",
        "\n",
        "    for name, model in best_base_estimators.items():\n",
        "        joblib.dump(model, os.path.join(RUN_SPECIFIC_PATH, f'tuned_base_model_{name}.joblib'))\n",
        "\n",
        "    joblib.dump(best_meta_model, os.path.join(RUN_SPECIFIC_PATH, 'tuned_meta_model.joblib'))\n",
        "    print(\"Tuned base and meta models saved successfully.\")\n",
        "\n",
        "    summary_report = {\n",
        "        'Final Performance Metrics': final_metrics,\n",
        "        'Best Base Model Parameters': best_base_params,\n",
        "        'Best Meta Model Parameters': best_meta_params\n",
        "    }\n",
        "    with open(os.path.join(RUN_SPECIFIC_PATH, 'summary_report.json'), 'w') as f:\n",
        "        json.dump(summary_report, f, indent=4)\n",
        "    with open(os.path.join(RUN_SPECIFIC_PATH, 'classification_report.txt'), 'w') as f:\n",
        "        f.write(report_str)\n",
        "    joblib.dump(DATA_DRIVEN_SPAM_VOCAB, os.path.join(RUN_SPECIFIC_PATH, 'spam_vocabulary.joblib'))\n",
        "    print(\"Performance reports, parameters, and vocabulary saved successfully.\")\n",
        "\n",
        "    print(\"\\nAll final artifacts have been saved.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "65i1SP-R-q-6",
        "outputId": "570a4ddb-a0b3-4c70-aa67-b08313769134"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "################################################################################\n",
            "# FINAL TUNED MODEL PERFORMANCE\n",
            "################################################################################\n",
            "Classification Report for the Tuned Model:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     Ham (0)       0.99      0.99      0.99     25540\n",
            "    Spam (1)       0.99      0.99      0.99     22923\n",
            "\n",
            "    accuracy                           0.99     48463\n",
            "   macro avg       0.99      0.99      0.99     48463\n",
            "weighted avg       0.99      0.99      0.99     48463\n",
            "\n",
            "\n",
            "Final Performance Metrics:\n",
            "- Tuned Accuracy: 0.9895\n",
            "- Tuned Spam F1-Score: 0.9889\n",
            "- Tuned MCC: 0.9789\n",
            "- Tuned AUC: 0.9993\n",
            "- Vectorization Time (ms): 13884\n",
            "- Prediction Time (ms): 20\n",
            "\n",
            "Hyperparameter tuning complete.\n",
            "\n",
            "--- Saving final artifacts... ---\n",
            "Final artifacts will be saved in: SpamClassifierProject_TunedStacking/tuned_run_2025-06-22_23-51-51\n",
            "Tuned base and meta models saved successfully.\n",
            "Performance reports, parameters, and vocabulary saved successfully.\n",
            "\n",
            "All final artifacts have been saved.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "**Assistance Disclosure:**\n",
        "\n",
        "I used LLMs (Codey, ChatGPT, Gemini, Claude, Grok) for brainstorming, debugging, feedback, and improving code readability."
      ],
      "metadata": {
        "id": "2uGpJHuCEVue"
      }
    }
  ]
}